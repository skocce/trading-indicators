{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e0685d3-8ad5-4cca-843c-6520a27177d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/skd/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['FB']: Exception('%ticker%: No timezone found, symbol may be delisted')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5675675675675675\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.80      0.67        40\n",
      "           1       0.56      0.29      0.38        34\n",
      "\n",
      "    accuracy                           0.57        74\n",
      "   macro avg       0.56      0.55      0.53        74\n",
      "weighted avg       0.56      0.57      0.54        74\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import yfinance as yf\n",
    "\n",
    "# Function to get historical stock data\n",
    "def get_stock_data(symbol, start_date, end_date):\n",
    "    stock = yf.download(symbol, start=start_date, end=end_date)\n",
    "    return stock['Adj Close']\n",
    "\n",
    "# Sample data - replace this with actual S&P500 company symbols and names\n",
    "s_and_p_500_data = {\n",
    "    'Symbol': ['AAPL', 'GOOGL', 'MSFT', 'AMZN', 'FB'],\n",
    "    'Company_Name': ['Apple Inc.', 'Alphabet Inc.', 'Microsoft Corp.', 'Amazon.com Inc.', 'Meta Platforms Inc.']\n",
    "}\n",
    "\n",
    "# Define the date range for historical stock data\n",
    "start_date = '2023-01-01'\n",
    "end_date = '2024-01-01'\n",
    "\n",
    "# Initialize a DataFrame for the analysis\n",
    "analysis_data = pd.DataFrame(index=pd.date_range(start_date, end_date))\n",
    "\n",
    "# Iterate through S&P500 symbols\n",
    "for i in range(len(s_and_p_500_data['Symbol'])):\n",
    "    symbol = s_and_p_500_data['Symbol'][i]\n",
    "    company_name = s_and_p_500_data['Company_Name'][i]\n",
    "\n",
    "    # Get historical stock data\n",
    "    stock_data = get_stock_data(symbol, start_date, end_date)\n",
    "\n",
    "    # Calculate daily percentage change for momentum\n",
    "    analysis_data[f'{symbol}_Momentum'] = stock_data.pct_change()\n",
    "\n",
    "    # Sentiment Analysis using NLTK's VaderSentiment\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    sentiment_scores = [sid.polarity_scores('Sample news')['compound'] for _ in range(len(analysis_data))]\n",
    "\n",
    "    # Add sentiment scores to the DataFrame\n",
    "    analysis_data[f'{symbol}_Sentiment'] = sentiment_scores\n",
    "\n",
    "# Define the target variable based on historical stock trends\n",
    "# For simplicity, let's say if the closing price increased (1) or decreased (0)\n",
    "analysis_data['Target'] = (analysis_data['AAPL_Momentum'].shift(-1) > 0).astype(int)\n",
    "\n",
    "# Machine Learning model training\n",
    "X = analysis_data[['AAPL_Momentum', 'AAPL_Sentiment', 'GOOGL_Momentum', 'GOOGL_Sentiment']]\n",
    "y = analysis_data['Target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Use the trained model to predict buy/hold/sell decisions\n",
    "predictions = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "classification_rep = classification_report(y_test, predictions)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\\n\", classification_rep)\n",
    "\n",
    "# You can add predictions to s_and_p_500_data if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf7b73a-f6b9-4f09-bec3-013f4f30a5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "83a05db4-8715-40c1-b3ad-66321b35c5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/skd/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['FB']: Exception('%ticker%: No timezone found, symbol may be delisted')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5969213226909921\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.79      0.71      1121\n",
      "           1       0.41      0.26      0.32       633\n",
      "\n",
      "    accuracy                           0.60      1754\n",
      "   macro avg       0.53      0.52      0.52      1754\n",
      "weighted avg       0.56      0.60      0.57      1754\n",
      "\n",
      "Excel file created: stock_analysis_results.xlsx\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import yfinance as yf\n",
    "\n",
    "# Function to get historical stock data\n",
    "def get_stock_data(symbol, start_date, end_date):\n",
    "    stock = yf.download(symbol, start=start_date, end=end_date)\n",
    "    return stock['Adj Close']\n",
    "\n",
    "# Sample data - replace this with actual S&P500 company symbols and names\n",
    "s_and_p_500_data = {\n",
    "    'Symbol': ['AAPL', 'GOOGL', 'MSFT', 'AMZN', 'FB'],\n",
    "    'Company_Name': ['Apple Inc.', 'Alphabet Inc.', 'Microsoft Corp.', 'Amazon.com Inc.', 'Meta Platforms Inc.']\n",
    "}\n",
    "\n",
    "# Define the date range for historical stock data\n",
    "start_date = '2000-01-01'\n",
    "end_date = '2024-01-01'\n",
    "\n",
    "# Initialize a DataFrame for the analysis\n",
    "analysis_data = pd.DataFrame(index=pd.date_range(start_date, end_date))\n",
    "\n",
    "# Iterate through S&P500 symbols\n",
    "for i in range(len(s_and_p_500_data['Symbol'])):\n",
    "    symbol = s_and_p_500_data['Symbol'][i]\n",
    "    company_name = s_and_p_500_data['Company_Name'][i]\n",
    "\n",
    "    # Get historical stock data\n",
    "    stock_data = get_stock_data(symbol, start_date, end_date)\n",
    "\n",
    "    # Calculate daily percentage change for momentum\n",
    "    analysis_data[f'{symbol}_Momentum'] = stock_data.pct_change()\n",
    "\n",
    "    # Sentiment Analysis using NLTK's VaderSentiment\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    sentiment_scores = [sid.polarity_scores('Sample news')['compound'] for _ in range(len(analysis_data))]\n",
    "\n",
    "    # Add sentiment scores to the DataFrame\n",
    "    analysis_data[f'{symbol}_Sentiment'] = sentiment_scores\n",
    "\n",
    "# Define the target variable based on historical stock trends\n",
    "# For simplicity, let's say if the closing price increased (1) or decreased (0)\n",
    "analysis_data['Target'] = (analysis_data['AAPL_Momentum'].shift(-1) > 0).astype(int)\n",
    "\n",
    "# Machine Learning model training\n",
    "X = analysis_data[['AAPL_Momentum', 'AAPL_Sentiment', 'GOOGL_Momentum', 'GOOGL_Sentiment']]\n",
    "y = analysis_data['Target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Use the trained model to predict buy/hold/sell decisions\n",
    "predictions = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "classification_rep = classification_report(y_test, predictions)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\\n\", classification_rep)\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "excel_file_path = 'stock_analysis_results.xlsx'\n",
    "analysis_data.to_excel(excel_file_path, index=True)\n",
    "\n",
    "# Display or export the analysis_data DataFrame with predictions and momentum\n",
    "print(f\"Excel file created: {excel_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573e623d-d368-4a67-ba35-29a49fbc9ee9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
